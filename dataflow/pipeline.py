import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
import argparse
import logging
import json
from datetime import datetime
import io

from google.cloud import storage
import vertexai
from vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold
from vertexai.preview.vision_models import ImageGenerationModel, Image

class GenerateContent(beam.DoFn):
    def __init__(self, project_id, region, product_images_bucket_name):
        self.project_id = project_id
        self.region = region
        self.product_images_bucket_name = product_images_bucket_name

    def setup(self):
        vertexai.init(project=self.project_id, location=self.region)
        self.text_model = GenerativeModel("gemini-2.5-pro", safety_settings={
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        })
        self.image_model = ImageGenerationModel.from_pretrained("imagegeneration@006")
        self.storage_client = storage.Client()

    def process(self, element):
        product_name = element['product_name']
        keywords = element['keywords']
        source_file = element['source_file']

        try:
            # 1. Generate Text
            prompt = f"Write a short, exciting marketing description for a product named '{product_name}' that is '{keywords}'. The description should be one paragraph."
            response = self.text_model.generate_content(prompt)

            if not response.candidates:
                generated_text = "Content blocked by safety filter."
            elif hasattr(response.candidates[0].content, 'text'):
                generated_text = response.candidates[0].content.text.strip()
            else:
                generated_text = "Error: No content generated by model."

            # 2. Generate Image
            generated_image_url = None
            if "Error:" not in generated_text and "Content blocked" not in generated_text:
                try:
                    image_prompt = f"A professional, high-resolution marketing photo, studio lighting, of: {generated_text}"
                    images = self.image_model.generate_images(
                        prompt=image_prompt,
                        number_of_images=1,
                    )

                    if images:
                        image_bytes = images[0]._image_bytes
                        image_blob_name = f"{product_name.replace(' ', '_').lower()}_{int(datetime.utcnow().timestamp())}.png"

                        image_bucket = self.storage_client.bucket(self.product_images_bucket_name)
                        image_blob = image_bucket.blob(image_blob_name)
                        image_blob.upload_from_file(io.BytesIO(image_bytes), content_type="image/png")

                        generated_image_url = image_blob.public_url
                except Exception as img_e:
                    logging.error(f"Failed to generate image for '{product_name}': {img_e}")
                    generated_image_url = "Error: Could not generate image."

            yield {
                "product_name": product_name,
                "keywords": keywords,
                "generated_content": generated_text,
                "generated_image_url": generated_image_url,
                "source_file": source_file,
                "processed_at": datetime.utcnow().isoformat()
            }
        except Exception as e:
            logging.error(f"Failed to generate content for '{product_name}': {e}")
            yield {
                "product_name": product_name,
                "keywords": keywords,
                "generated_content": "Error: Could not generate content due to an exception.",
                "generated_image_url": "Error: Could not generate image.",
                "source_file": source_file,
                "processed_at": datetime.utcnow().isoformat()
            }

def run():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_subscription', required=True)
    parser.add_argument('--output_table', required=True)
    parser.add_argument('--product_images_bucket_name', required=True)
    parser.add_argument('--project_id', required=True)
    parser.add_argument('--region', required=True)

    known_args, pipeline_args = parser.parse_known_args()
    pipeline_options = PipelineOptions(pipeline_args)

    with beam.Pipeline(options=pipeline_options) as p:
        (p | 'Read from Pub/Sub' >> beam.io.ReadFromPubSub(subscription=known_args.input_subscription)
           | 'Decode' >> beam.Map(lambda x: json.loads(x.decode('utf-8')))
           | 'Generate Content' >> beam.ParDo(GenerateContent(known_args.project_id, known_args.region, known_args.product_images_bucket_name))
           | 'Write to BigQuery' >> beam.io.WriteToBigQuery(
               known_args.output_table,
               schema='product_name:STRING,keywords:STRING,generated_content:STRING,generated_image_url:STRING,source_file:STRING,processed_at:TIMESTAMP',
               write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,
               create_disposition=beam.io.BigQueryDisposition.CREATE_NEVER
           )
        )

if __name__ == '__main__':
    logging.getLogger().setLevel(logging.INFO)
    run()
